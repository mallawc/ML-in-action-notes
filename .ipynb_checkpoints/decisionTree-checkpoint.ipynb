{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e0eb6b",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "### 概念\n",
    "决策树是一种**预测模型**，代表的是对象（特征）属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值，而每个叶节点则对应从根节点到该叶节点所经历的路径所表示的对象的值。\n",
    "\n",
    "从数据产生决策树的ML技术叫做“决策树学习”，目的是从训练数据集种归纳出一组分类规则.\n",
    "\n",
    "#### 表示：\n",
    "\n",
    "**判断模块（decision block）**：针对属性进行判断\n",
    "\n",
    "**终止模块（terminating block）**：表示已经得出结论，可以终止运行\n",
    "\n",
    "**分支（branch）**：可以到达另一个判断模块或终止模块\n",
    "\n",
    "根节点：\n",
    "\n",
    "内部节点：也称决策节点\n",
    "\n",
    "叶节点：\n",
    "\n",
    "#### 基本流程：\n",
    "决策树是一个由根到叶的**递归过程**，在每一个中间结点寻找划分属性，递归重要的是设置**停止条件**：\n",
    "\n",
    "（1）当前结点包含的样本属于同一类别，无需划分；\n",
    "\n",
    "（2）当前属性集为空，或是所有样本在所有属性上取值相同无法划分，简单理解就是当分到这一节点时，所有的属性特征都用完了，没有特征可用了，就根据label数量多的给这一节点打标签使其变成叶节点（其实是在用样本出现的后验概率做先验概率）；\n",
    "\n",
    "（3）当前结点包含的样本集合为空，不能划分。这种情况出现是因为该样本数据缺少这个属性取值，根据父结点的label情况为该结点打标记（其实是在用父结点出现的后验概率做该结点的先验概率）。\n",
    "\n",
    "\n",
    "#### 目标：\n",
    "构造的算法能够读取数据集合，构建出一棵决策树。由于决策树很多任务都是为了数据中所蕴含的知识信息，因此决策树可以使用不熟悉的数据集合，并从中提取出一系列规则，ML算法最终将使用这些规则。\n",
    "\n",
    "\n",
    "### 决策树ML算法构建流程：\n",
    "（1）**收集数据**：可以用任何方法\n",
    "\n",
    "（2）**准备数据**：树构造算法只适用于标称型数据（在有限的数据中取，结果只有y或n，一般用于分类），因此数值型数据必须离散化\n",
    "\n",
    "（3）**分析数据**：可以使用任何方法，构造树完成之后，应检查图形是否符合预期\n",
    "\n",
    "（4）**训练算法**：构造树的数据结构\n",
    "\n",
    "（5）**测试算法**：使用经验树计算错误率\n",
    "\n",
    "（6）**使用算法**：可适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义!\n",
    "\n",
    "### 决策树的构造\n",
    "\n",
    "#### 1、（关键）讨论数学上如何使用*信息论*划分属性：\n",
    "当前数据集上哪个特征在划分数据分类时起决定性作用。决定性的特征能划分出最好的结果，所以必须**评估每个特征**。完成评估测试后，原始数据集就被划分为几个数据子集，并分布在第一个决策点的所有分支上。**若某个分支下的所有数据都属于同一类型（用类别标签判断），则说明当前已经正确划分数据分类，无需进一步对数据集进行分割；若数据子集内的数据不属于同一类型，则需要重复划分数据子集的过程（是一个递归过程），直到所有具有相同类型的数据均在一个数据子集内.**\n",
    "\n",
    "属性划分过程由创建分支的递归函数**createBranch**完成：\n",
    "```cpp\n",
    "if so return <类别标签>;\n",
    "else\n",
    "    寻找划分数据集的最好特征\n",
    "    划分数据集\n",
    "    创建分支节点\n",
    "        for 每个划分的子集\n",
    "            调用函数createBranch()并增加返回结果到分支节点中\n",
    "    return 分支节点\n",
    "```\n",
    "实际上我们使用**ID3算法**划分数据集，该算法处理如何划分数据集、何时停止划分数据集。每次划分数据集时我们只选取一个特征属性。如果训练集中存在20个特征，**第一次应该选择哪个特征作为划分的参考属性？** 所以必须使用量化的方法（香农熵）判断如何划分数据.\n",
    "\n",
    "<mark>**划分数据集的最大原则：将无序的数据变得更加有序**.</mark>组织杂乱数据的一种方法是：使用信息论度量信息(信息论是决策树的数学基础).\n",
    "\n",
    "划分数据集前后信息发生的变化称为“**信息增益**”（information gain），通过计算每个特征值划分数据集后获得的信息增益，**增益最高的特征就是最好的选择**.在决策树学习中，信息增益是特征选择的一个重要指标，它定义为一个特征能够为分类系统带来多少信息，信息越多，说明特征越重要.\n",
    "\n",
    "##### 1.1、熵（Entropy）\n",
    "用于描述事件的不确定性，单位是bit.若某个事件有$n$个结果，每个结果的概率为 $p_n$。那么这个事件的熵$H(p)$的定义为：\n",
    "\n",
    "$$H(p)=-\\sum_{i=1}^{n}p_i\\log_2{p_i}$$\n",
    "\n",
    "熵越大含有的信息量就越大，不确定性更强.\n",
    "\n",
    "##### 1.2、条件熵\n",
    "在某些条件下，不确定性会发生变化.条件熵衡量的是在某个条件$X$下，事件$Y$的不确定性，记作$H(Y|X)$.其定义为：\n",
    "\n",
    "$$H(Y|X)=\\sum_{i=1}^{n}p_iH(Y|X=x_i)$$\n",
    "\n",
    "可理解为，$X$事件每个可能性的结果的熵乘以发生概率的求和.\n",
    "\n",
    "##### 1.3、信息增益（Information gain）\n",
    "信息增益是在知道某个条件后，事件的不确定性下降程度，记作$g(X,Y)$.计算方式为熵减去条件熵：\n",
    "\n",
    "$$g(X,Y)=H(Y)-H(Y|X)$$\n",
    "\n",
    "表示的是，知道了某个条件后，原来事件不确定性降低的幅度.\n",
    "\n",
    "##### 1.4、信息增益率\n",
    "分析可知，信息增益其实是对可取数目较多的属性有所偏好。所以信息增益并不是一个很好的特征选择度量，于是引出了信息增益率。\n",
    "\n",
    "$g_r$即$Gain\\_ratio$，$H(Y)$是（特征）属性的固有值\n",
    "\n",
    "$$g_r(X,Y)=\\frac{g(X,Y)}{H(Y)}$$\n",
    "\n",
    "##### 1.5、基尼系数\n",
    "与熵一样，基尼系数表征的也是事件的不确定性，将熵定义式中的“$-\\log_{2}p_i$”替换为 “$1-p_i$”就是基尼系数.\n",
    "\n",
    "$$Gini(p)=\\sum_{i=1}^{n}p_i(1-p_i)$$\n",
    "\n",
    "变形：\n",
    "\n",
    "$$Gini(p)=\\sum_{i=1}^{n}(p_i-p_i^2)=1-\\sum_{i=1}^{n}p_i^2$$\n",
    "\n",
    "\n",
    "\n",
    "#### 2、编写代码将理论应用到具体的数据集上：\n",
    "计算给定数据集的香农熵：$n$为分类条目\n",
    "$$H(p)=-\\sum_{i=1}^{n}p_i\\log_2{p_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16bd6d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    # 统计每组特征向量\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]\n",
    "        # 如果标签没有放入统计次数的字典，添加进去\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        shannonEnt -= prob * log(prob,2)\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d91cb3",
   "metadata": {},
   "source": [
    "##### 示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d4a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    dataSet = [[0, 0, 0, 0, 'no'],\n",
    "            [0, 0, 0, 1, 'no'],\n",
    "            [0, 1, 0, 1, 'yes'],\n",
    "            [0, 1, 1, 0, 'yes'],\n",
    "            [0, 0, 0, 0, 'no'],\n",
    "            [1, 0, 0, 0, 'no'],\n",
    "            [1, 0, 0, 1, 'no'],\n",
    "            [1, 1, 1, 1, 'yes'],\n",
    "            [1, 0, 1, 2, 'yes'],\n",
    "            [1, 0, 1, 2, 'yes'],\n",
    "            [2, 0, 1, 2, 'yes'],\n",
    "            [2, 0, 1, 1, 'yes'],\n",
    "            [2, 1, 0, 1, 'yes'],\n",
    "            [2, 1, 0, 2, 'yes'],\n",
    "            [2, 0, 0, 0, 'no']]\n",
    "    #分类属性\n",
    "    labels = ['年龄', '有工作', '有自己的房子', '信贷情况']\n",
    "    #返回数据集和分类属性\n",
    "    return dataSet, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40318178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 'no'], [0, 0, 0, 1, 'no'], [0, 1, 0, 1, 'yes'], [0, 1, 1, 0, 'yes'], [0, 0, 0, 0, 'no'], [1, 0, 0, 0, 'no'], [1, 0, 0, 1, 'no'], [1, 1, 1, 1, 'yes'], [1, 0, 1, 2, 'yes'], [1, 0, 1, 2, 'yes'], [2, 0, 1, 2, 'yes'], [2, 0, 1, 1, 'yes'], [2, 1, 0, 1, 'yes'], [2, 1, 0, 2, 'yes'], [2, 0, 0, 0, 'no']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat, labels = createDataSet()\n",
    "print(myDat)\n",
    "calcShannonEnt(myDat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2613f20",
   "metadata": {},
   "source": [
    "完成使用Shannon熵度量数据集的无序程度后，分类算法已经能够判断当前是否正确划分了数据集的依据（可以想象为一个分布在二维空间的数据散点图，需要在数据之间划一道线，将其分成两部分，划得好不好已经有了判断方法了）."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e7d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet, axis, value):\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "            \n",
    "    return retDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a722be3c",
   "metadata": {},
   "source": [
    "#### 3、编写代码构建决策树：\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
